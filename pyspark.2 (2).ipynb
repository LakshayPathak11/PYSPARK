{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff04d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fe6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "54f2b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ef83113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=spark.read.format('csv').\\\n",
    "option ('inferSchema','true').\\\n",
    "option ('header','true').\\\n",
    "option ('path','data.csv').\\\n",
    "load()\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f58eb",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "479cd6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c78279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "293fb1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|   A|\n",
      "|   B|\n",
      "|   C|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "075ef9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|name|Experience|\n",
      "+----+----------+\n",
      "|   A|        10|\n",
      "|   B|         8|\n",
      "|   C|         4|\n",
      "+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(['name', 'Experience', ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d7e628a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, Name: string, Age: string, Experience: string]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7ff01ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+-----------------+\n",
      "|summary|Name| Age|       Experience|\n",
      "+-------+----+----+-----------------+\n",
      "|  count|   3|   3|                3|\n",
      "|   mean|null|30.0|7.333333333333333|\n",
      "| stddev|null| 1.0|3.055050463303893|\n",
      "|    min|   A|  29|                4|\n",
      "|    max|   C|  31|               10|\n",
      "+-------+----+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0804ac73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------------+\n",
      "|Name|Age|Experience|after 2 year|\n",
      "+----+---+----------+------------+\n",
      "|   A| 31|        10|          12|\n",
      "|   B| 30|         8|          10|\n",
      "|   C| 29|         4|           6|\n",
      "+----+---+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.withColumn('after 2 year',data['Experience']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d0ee62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+----------+------+\n",
      "|Name|Age|Experience|Gender|\n",
      "+----+---+----------+------+\n",
      "|   A| 31|        10|     M|\n",
      "|   B| 30|         8|     M|\n",
      "|   C| 29|         4|     M|\n",
      "+----+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.withColumn('Gender',lit('M')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d75a56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "405750e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-----------------+----------+------+\n",
      "|     ip_address|       Country|      Domain Name|Bytes_used|Gender|\n",
      "+---------------+--------------+-----------------+----------+------+\n",
      "|  52.81.192.172|         China| odnoklassniki.ru|       463|     M|\n",
      "| 119.239.207.13|         China|         youtu.be|        51|     M|\n",
      "|  68.69.217.210|         China|        adobe.com|        10|     M|\n",
      "|   7.191.21.223|      Bulgaria|     linkedin.com|       853|     M|\n",
      "|   211.13.10.68|     Indonesia|          hud.gov|        29|     M|\n",
      "|   239.80.21.97|      Suriname|       smh.com.au|       218|     M|\n",
      "|106.214.106.233|       Jamaica|    amazonaws.com|        95|     M|\n",
      "| 127.242.24.138|         China| surveymonkey.com|       123|     M|\n",
      "|     99.2.6.139|Czech Republic|     geocities.jp|       322|     M|\n",
      "|   237.54.11.63|         China|       amazon.com|        83|     M|\n",
      "| 252.141.157.25|         Japan|      cornell.edu|       374|     M|\n",
      "|185.220.128.248|       Belgium|       weebly.com|       389|     M|\n",
      "|   151.77.19.45|   Afghanistan|independent.co.uk|       282|     M|\n",
      "|  9.161.158.225|     Indonesia|    bloglines.com|       726|     M|\n",
      "| 156.144.61.155|Czech Republic|   slideshare.net|       657|     M|\n",
      "|   8.96.188.151|     Indonesia|          ibm.com|       517|     M|\n",
      "|      5.72.7.65|        Mexico|         youtu.be|       877|     M|\n",
      "|227.110.112.144|       Croatia|         ehow.com|       287|     M|\n",
      "|    81.71.28.97|      Thailand|          last.fm|       588|     M|\n",
      "|  9.255.129.184|      Thailand|          mtv.com|       114|     M|\n",
      "+---------------+--------------+-----------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.withColumn(\"Gender\", lit('M')) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5b78ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70af0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ip_address: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Domain Name: string (nullable = true)\n",
      " |-- Bytes_used: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=spark.read.format('csv').\\\n",
    "option ('inferSchema','true').\\\n",
    "option ('header','true').\\\n",
    "option ('path','assignment 2 - Pyspark.csv').\\\n",
    "load()\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bd5e7e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|       Country|\n",
      "+--------------+\n",
      "|         China|\n",
      "|         China|\n",
      "|         China|\n",
      "|      Bulgaria|\n",
      "|     Indonesia|\n",
      "|      Suriname|\n",
      "|       Jamaica|\n",
      "|         China|\n",
      "|Czech Republic|\n",
      "|         China|\n",
      "|         Japan|\n",
      "|       Belgium|\n",
      "|   Afghanistan|\n",
      "|     Indonesia|\n",
      "|Czech Republic|\n",
      "|     Indonesia|\n",
      "|        Mexico|\n",
      "|       Croatia|\n",
      "|      Thailand|\n",
      "|      Thailand|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select('Country').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5ed7ac7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------+-----------------+----------+--------+\n",
      "|     ip_address|       Country|      Domain Name|Bytes_used|Country1|\n",
      "+---------------+--------------+-----------------+----------+--------+\n",
      "|  52.81.192.172|         China| odnoklassniki.ru|       463|      No|\n",
      "| 119.239.207.13|         China|         youtu.be|        51|      No|\n",
      "|  68.69.217.210|         China|        adobe.com|        10|      No|\n",
      "|   7.191.21.223|      Bulgaria|     linkedin.com|       853|      No|\n",
      "|   211.13.10.68|     Indonesia|          hud.gov|        29|      No|\n",
      "|   239.80.21.97|      Suriname|       smh.com.au|       218|      No|\n",
      "|106.214.106.233|       Jamaica|    amazonaws.com|        95|      No|\n",
      "| 127.242.24.138|         China| surveymonkey.com|       123|      No|\n",
      "|     99.2.6.139|Czech Republic|     geocities.jp|       322|      No|\n",
      "|   237.54.11.63|         China|       amazon.com|        83|      No|\n",
      "| 252.141.157.25|         Japan|      cornell.edu|       374|      No|\n",
      "|185.220.128.248|       Belgium|       weebly.com|       389|      No|\n",
      "|   151.77.19.45|   Afghanistan|independent.co.uk|       282|      No|\n",
      "|  9.161.158.225|     Indonesia|    bloglines.com|       726|      No|\n",
      "| 156.144.61.155|Czech Republic|   slideshare.net|       657|      No|\n",
      "|   8.96.188.151|     Indonesia|          ibm.com|       517|      No|\n",
      "|      5.72.7.65|        Mexico|         youtu.be|       877|     Yes|\n",
      "|227.110.112.144|       Croatia|         ehow.com|       287|      No|\n",
      "|    81.71.28.97|      Thailand|          last.fm|       588|      No|\n",
      "|  9.255.129.184|      Thailand|          mtv.com|       114|      No|\n",
      "+---------------+--------------+-----------------+----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as sql\n",
    "from pyspark.sql.functions import *\n",
    "df=data.withColumn(\"Country1\", when(data.Country== \"Mexico\" , \"Yes\").otherwise(\"No\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "85d28932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.groupBy('Country1').agg(sum('Bytes_used').alias('total_bytes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5422aaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|Country1|total_bytes|\n",
      "+--------+-----------+\n",
      "|      No|     508076|\n",
      "|     Yes|       6293|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "700ee4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|Country1|distinct_ip_count|\n",
      "+--------+-----------------+\n",
      "|      No|              987|\n",
      "|     Yes|               13|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "import pyspark.sql.functions as sql\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Assuming you already have a SparkSession created and a DataFrame named 'df'\n",
    "# spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "# df = spark.read...\n",
    "\n",
    "df_result = df.groupBy('Country1').agg(countDistinct('ip_address').alias('distinct_ip_count'))\n",
    "\n",
    "# Show or perform further actions on df_result as needed\n",
    "df_result.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4c1acfe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Country1: string, distinct_ip_count: bigint]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.orderBy(col('distinct_ip_count').desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32a8f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|Country1|distinct_ip_count|\n",
      "+--------+-----------------+\n",
      "|      No|              987|\n",
      "|     Yes|               13|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eeb072d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ed64e3",
   "metadata": {},
   "source": [
    "# user defined functions in Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "64618ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11df8b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"DataFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6225eaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- bonus: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data= spark.read.format('csv').\\\n",
    "option('inferSchema','true').\\\n",
    "option('header','true').\\\n",
    "option('path','file1.csv').\\\n",
    "load()\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6fd77fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+-----+\n",
      "| id|    name|salary|bonus|\n",
      "+---+--------+------+-----+\n",
      "|  1|manpreet| 50000|  200|\n",
      "|  2|   payal| 80000|  300|\n",
      "+---+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ca21440a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3ded6791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c0e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440ebbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f9e23e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def totpay(s, b):\n",
    "    return s + b\n",
    "\n",
    "TotalPayment = udf(lambda salary, bonus: totpay(salary, bonus), IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c04650",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450497ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Assuming you already have a SparkSession created and a DataFrame named 'df'\n",
    "# spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "# df = spark.read...\n",
    "\n",
    "def totpay(s, b):\n",
    "    return s + b\n",
    "\n",
    "TotalPayment = udf(lambda salary, bonus: totpay(salary, bonus), IntegerType())\n",
    "\n",
    "# Add a new column 'TotalPay' to the DataFrame\n",
    "result = data.withColumn('TotalPay', TotalPayment(data.salary, data.bonus))\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9c8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = result.toPandas()\n",
    "print(df_pandas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f062144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
