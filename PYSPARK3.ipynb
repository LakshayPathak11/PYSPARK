{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9656bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe17672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5263efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a4bebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "795541f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      " |-- BONUS: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=spark.read.format('csv').\\\n",
    "option('inferschema','true').\\\n",
    "option('header','true').\\\n",
    "option('path','pysparkdata.csv').load()\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10bf1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+------+-----+\n",
      "| ID|NAME|SALARY|BONUS|\n",
      "+---+----+------+-----+\n",
      "|  1|Arun| 20000| 3000|\n",
      "|  2|  Aj| 30000| 5000|\n",
      "+---+----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69056dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalpay(SALARY,BONUS):\n",
    "    return(SALARY+BONUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75454d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalpay(20000,3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07b2da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Assuming you already have a SparkSession created and a DataFrame named 'df'\n",
    "# spark = SparkSession.builder.appName(\"example\").getOrCreate()\n",
    "# df = spark.read...\n",
    "\n",
    "def totpay(s, b):\n",
    "    return s + b\n",
    "\n",
    "TotalPayment = udf(lambda salary, bonus: totpay(salary, bonus), IntegerType())\n",
    "\n",
    "# Add a new column 'TotalPay' to the DataFrame\n",
    "result = data.withColumn('TotalPay', TotalPayment(data.SALARY, data.BONUS))\n",
    "\n",
    "# Show the resulting DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567fabb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
